# LLM-Detecting-AI-Generated-Text-with-Tiny-Bert

# Goal
The goal of this notebook is to build and evaluate a machine learning model that can accurately detect whether a given text is generated by a Large Language Model (LLM) or written by a human. The project aims to use a lightweight, efficient model (TinyBERT) to tackle the AI-generated text detection problem using a public dataset.

# Description
This notebook walks through the end-to-end process of detecting AI-generated text. It begins by loading and exploring a dataset containing both AI-generated and human-written texts. The dataset is sampled and stratified to maintain class proportions and split into training and validation sets.

A pre-trained TinyBERT model is fine-tuned for binary classification (AI-generated vs. human). The notebook details the process, including data tokenization, model parameter tuning (freezing most layers except the classifier and the last encoder layer), and the training loop with cross-entropy loss. Model performance is evaluated using predicted probabilities, confusion matrix, and classification metrics such as precision, recall, and F1-score. Finally, the trained model is saved for future use.

# Tools
- Python (Jupyter Notebook)
- Data Science Libraries: numpy, pandas, matplotlib, seaborn

- Machine Learning Libraries:
  - scikit-learn (for data splitting and metrics)
  - PyTorch (for model training, data handling, and saving)
  - Transformers Library: HuggingFace Transformers (for TinyBERT, tokenization, and model loading)
- Dataset: LLM Detect AI Generated Text Dataset from [Kaggle](https://www.kaggle.com/datasets/sunilthite/llm-detect-ai-generated-text-dataset )
